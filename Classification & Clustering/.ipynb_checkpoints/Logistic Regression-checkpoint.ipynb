{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Session: Logistic Regression in R \n",
    " Created By: Ujjwal Karn           \n",
    " Date: 05-Oct-2015                 \n",
    "\n",
    "\n",
    "# Topics Covered\n",
    "\n",
    "1. Reading data and Summary Statistics\n",
    "2. Outlier Detection\n",
    "3. Missing Value Treatment\n",
    "4. Correlation and VIF\n",
    "5. Feature Selection Using IV \n",
    "6. Creating Training and validation Sets\n",
    "7. Running the Logistic Model on Training Set\n",
    "8. Evaluating Performance on Validation Set\n",
    "        a. ROC and AUC\n",
    "        b. Confusion Matrix\n",
    "        c. KS Statistic\n",
    "9. Scoring the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading data and Summary Statistics\n",
    "\n",
    "#change the working directory\n",
    "setwd(\".\")\n",
    "     \n",
    "train_data<-read.csv(\"data/train.csv\")\n",
    "test_data<-read.csv(\"data/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "install.packages(c('usdm','plyr','rpart','sqldf','e1071'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Summary Statistics\n",
    "head(train_data)\n",
    "str(train_data)\n",
    "summary(train_data)\n",
    "describe(train_data)\n",
    "\n",
    "head(test_data)\n",
    "str(test_data)\n",
    "summary(test_data)\n",
    "\n",
    "# 2-way contingency tables\n",
    "xtabs(~admit + prestige, data = train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier Detection\n",
    "sapply(train_data[,1:3], function(x) quantile(x, c(.01,.05,.25,.5,.75,.90,.95, .99, 1),na.rm=TRUE) )\n",
    "\n",
    "#gpa of 6.5 seems to be an outlier\n",
    "train_data$gpa[train_data$gpa > 4] <- 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Value Imputation\n",
    "\n",
    "sapply(train_data, function(x) sum(is.na(x)) )\n",
    "train_data$gre[is.na(train_data$gre)] <- mean(train_data$gre, na.rm=TRUE)\n",
    "\n",
    "train_data2<-train_data\n",
    "\n",
    "sapply(train_data2, function(x) train_data2[,x][is.na(train_data2[,x])]<- mean(train_data2[,x], na.rm=TRUE))\n",
    "# this cell prints a lot of logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation and VIF \n",
    "\n",
    "library(usdm)\n",
    "\n",
    "cor(train_data[,1:3])\n",
    "\n",
    "vif(train_data[,1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information Value \n",
    "\n",
    "library(plyr)\n",
    "library(sqldf)\n",
    "library(rpart)\n",
    "\n",
    "#source(\"others/xyz.R\")\n",
    "\n",
    "file.sources = list.files(\"others\", full.names=TRUE)\n",
    "sapply(file.sources,source,.GlobalEnv)\n",
    "\n",
    "data <- train_data\n",
    "data$admit <- factor(data$admit, levels= c(\"1\",\"0\"))\n",
    "levels(data$admit)\n",
    "\n",
    "str(data)\n",
    "iv.mult(data, y=\"admit\", vars=c(\"gre\",\"gpa\",\"prestige\"), summary=\"TRUE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and validation sets \n",
    "\n",
    "set.seed(123)\n",
    "smp_size <- floor(0.7 * nrow(train_data))\n",
    "\n",
    "train_ind <- sample(seq_len(nrow(train_data)), size = smp_size)\n",
    "\n",
    "training <- train_data[train_ind, ]\n",
    "validation <- train_data[-train_ind, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the Logistic Model on Training set \n",
    "\n",
    "?lm\n",
    "?describe\n",
    "?glm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "admit ~ gre + gpa + prestige\n",
    "\n",
    "mylogit <- glm(admit ~ gre + gpa + prestige, data = training, family = \"binomial\")\n",
    "\n",
    "mylogit2 <- glm(admit ~ gpa + prestige, data = training, family = \"binomial\")\n",
    "\n",
    "summary(mylogit2)\n",
    "# See how prestige has been used as a dummy variable\n",
    "\n",
    "confint(mylogit, level=.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caluclating Concordance\n",
    "# Refer to the blog here to see  about Concordance\n",
    "# http://shashiasrblog.blogspot.in/2014/02/binary-logistic-regression-fast.html\n",
    "\n",
    "fastConc<-function(model){\n",
    "  # Get all actual observations and their fitted values into a frame\n",
    "  fitted<-data.frame(cbind(model$y,model$fitted.values))\n",
    "  colnames(fitted)<-c('respvar','score')\n",
    "  # Subset only ones\n",
    "  ones<-fitted[fitted[,1]==1,]\n",
    "  # Subset only zeros\n",
    "  zeros<-fitted[fitted[,1]==0,]\n",
    "  \n",
    "  # Initialise all the values\n",
    "  pairs_tested<-nrow(ones)*nrow(zeros)\n",
    "  conc<-0\n",
    "  disc<-0\n",
    "  \n",
    "  # Get the values in a for-loop\n",
    "  for(i in 1:nrow(ones))\n",
    "  {\n",
    "    conc<-conc + sum(ones[i,\"score\"]>zeros[,\"score\"])\n",
    "    disc<-disc + sum(ones[i,\"score\"]<zeros[,\"score\"])\n",
    "  }\n",
    "  # Calculate concordance, discordance and ties\n",
    "  concordance<-conc/pairs_tested\n",
    "  discordance<-disc/pairs_tested\n",
    "  ties_perc<-(1-concordance-discordance)\n",
    "  return(list(\"Concordance\"=concordance,\n",
    "              \"Discordance\"=discordance,\n",
    "              \"Tied\"=ties_perc,\n",
    "              \"Pairs\"=pairs_tested))\n",
    "}\n",
    "\n",
    "\n",
    "fastConc(mylogit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Performance on the Validation Set \n",
    "\n",
    "val <-predict(mylogit, validation, type=\"response\") \n",
    "\n",
    "mydf <-cbind(validation,val)\n",
    "\n",
    "mydf$response <- as.factor(ifelse(mydf$val>0.5, 1, 0))\n",
    "\n",
    "\n",
    "library(ROCR)\n",
    "logit_scores <- prediction(predictions=mydf$val, labels=mydf$admit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLOT ROC CURVE\n",
    "logit_perf <- performance(logit_scores, \"tpr\", \"fpr\")\n",
    "plot(logit_perf,col = \"darkblue\",lwd=2,xaxs=\"i\",yaxs=\"i\",tck=NA, main=\"ROC Curve\")\n",
    "box()\n",
    "abline(0,1, lty = 300, col = \"green\")\n",
    "grid(col=\"aquamarine\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AREA UNDER THE CURVE\n",
    "logit_auc <- performance(logit_scores, \"auc\")\n",
    "as.numeric(logit_auc@y.values)  ##AUC Value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONFUSION MATRIX\n",
    "library(caret)\n",
    "confusionMatrix(mydf$response,mydf$admit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### KS STATISTIC\n",
    "logit_ks <- max(logit_perf@y.values[[1]]-logit_perf@x.values[[1]])\n",
    "logit_ks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LIFT CHART\n",
    "lift.obj <- performance(logit_scores, measure=\"lift\", x.measure=\"rpp\")\n",
    "plot(lift.obj,\n",
    "     main=\"Lift Chart\",\n",
    "     xlab=\"% Populations\",\n",
    "     ylab=\"Lift\",\n",
    "     col=\"blue\")\n",
    "abline(1,0,col=\"grey\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#GAINS TABLE\n",
    "install.packages(\"gains\")\n",
    "library(gains)\n",
    "# gains table\n",
    "gains.cross <- gains(actual=mydf$admit , predicted=mydf$val, groups=10)\n",
    "print(gains.cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scoring the Test Data using the model we just created \n",
    "\n",
    "pred <- predict(mylogit, test_data, type=\"response\") \n",
    "final <- cbind(test_data,pred)\n",
    "\n",
    "write.csv(final,\"final_probs.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REFERENCE MATERIAL\n",
    "\t\n",
    "http://www.ats.ucla.edu/stat/r/dae/logit.htm \n",
    "\n",
    "http://www.unc.edu/courses/2010fall/ecol/563/001/notes/lecture21%20Rcode.html \n",
    "\n",
    "Caret Package: http://topepo.github.io/caret/ \n",
    "\n",
    "http://www.r-bloggers.com/gini-index-and-lorenz-curve-with-r/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
