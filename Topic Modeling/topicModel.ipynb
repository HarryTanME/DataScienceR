{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tm)\n",
    "require(lda)\n",
    "\n",
    "dataValues<- read.csv('comments.csv')\n",
    "dataValues=dataValues[sample(nrow(dataValues),size=10000,replace=FALSE),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(dataValues)\n",
    "## Text Pre-processing.\n",
    "## Creating a Corpus from the Orginal Function\n",
    "## interprets each element of the vector x as a document\n",
    "CorpusObj<- VectorSource(dataValues$message);\n",
    "CorpusObj<-Corpus(CorpusObj);\n",
    "CorpusObj <- tm_map(CorpusObj, tolower) # convert all text to lower case\n",
    "CorpusObj <- tm_map(CorpusObj, removePunctuation) \n",
    "CorpusObj <- tm_map(CorpusObj, removeNumbers)\n",
    "inspect(CorpusObj[1:100])\n",
    "\n",
    "myStopwords<-c(\"custom words\",stopwords(\"english\"))\n",
    "\n",
    "CorpusObj <- tm_map(CorpusObj, removeWords,myStopwords) \n",
    "CorpusObj <- tm_map(CorpusObj, stemDocument, language = \"english\") ## Stemming the words \n",
    "CorpusObj<-tm_map(CorpusObj,stripWhitespace)\n",
    "\n",
    "gsub(\"[^A-Za-z]\", \"\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusLDA <- lexicalize(CorpusObj )\n",
    "\n",
    "ldaModel=lda.collapsed.gibbs.sampler(corpusLDA$documents,K=5,vocab=corpusLDA$vocab,burnin=9999,num.iterations=1000,alpha=0.7,eta=0.1)\n",
    "top.words <- top.topic.words(ldaModel$topics, 8, by.score=TRUE)\n",
    "print(top.words) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
